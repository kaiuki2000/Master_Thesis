%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                      %
%     File: Base_Algorithm.tex                                      %
%     Tex Master: Thesis.tex                                           %
%                                                                      %
%     Author: Andre C. Marta                                           %
%     Last modified :  4 Mar 2024                                      %
%                                                                      %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Base iQAQE Algorithm}
\label{chapter:Base Algorithm}

To motivate the development of this algorithm, let us summarize the merits and drawbacks of both \acrshort{qaoa} and \acrshort{qemc}. \acrshort{qemc} boasts several advantages over \acrshort{qaoa}, including significantly lower qubit requirements ($n = \log_2(N)$ \textit{vs.} $N$) and the ability to accommodate shallower circuit depths \cite{tenecohen2023variational}. Additionally, the threshold probability encoding scheme allows \acrshort{qemc} to associate each graph partition with a volume of quantum states, potentially enhancing noise resilience. Furthermore, it is also believed that \acrshort{qemc} might be better trainable \cite{tenecohen2023variational}. Conversely, \acrshort{qemc} demands the entire probability distribution at each optimization step (to compute the cost), resulting in an overall increase in the number of needed shots when compared to \acrshort{qaoa}, which solely necessitates expectation values. However, as we've mentioned before, it has been shown \cite{tenecohen2023variational} that \acrshort{qemc} can be efficiently simulated entirely classically, somewhat undermining its purpose as a quantum algorithm.

With a thorough grasp of these two algorithms, the \textit{HQCC} project collaboration has put forward a novel, hybrid algorithm that integrates aspects from both, intending to capitalize on their individual strengths for a more substantial outcome. This is what we will be discussing next.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Interpolated QAOA/QEMC Hybrid Algorithm (iQAQE)}
\label{section:iQAQE}

\subsection{Theoretical Framework}
\label{subsection:iQAQE Theoretical Framework}
The proposed algorithm aspires to act as an interpolation between \acrshort{qaoa} and \acrshort{qemc}, aiming to amalgamate the strengths of both into a more robust approach, tentatively named \acrshort{iqaqe} (Interpolated QAOA/QEMC). In \acrshort{iqaqe}, we depart from the \acrshort{qemc} approach by associating each graph node with a list of basis states, in contrast to \acrshort{qemc}'s consideration of a single basis state for each node. Each of these lists comprises somewhere between $\left[1, 2^{N}-1\right]$ basis states, where $N$ represents the number of nodes. This design allows for potential overlap among states from different lists/nodes. Additionally, it is important to note that the encoding of these states will utilize a qubit range expected to fall between the \acrshort{qemc} and \acrshort{qaoa} requirements, specifically in $[\log_2{N}, N]$. With all that said, the main goal of my thesis is to ascertain the optimal mapping from basis states to lists, essentially determining which basis states should be included in specific lists/nodes. Naturally, this undertaking also involves the identification of a suitable cost function and ansatz to ensure the algorithm's effective operation.

\subsection{Motivation \& Outlook}
\label{subsection:iQAQE Motivation}
At this point, it is important to mention that the development of this algorithm is entirely exploratory, although we do believe it should allow for a more practical algorithm implementation-wise. We can postulate that such an hybrid approach might have some potential advantages. Namely, it should allow for less shots than in \acrshort{qemc}, and fewer qubit requirements than in \acrshort{qaoa}, in addition to, arguably, being better trainable. Another interesting characteristic of such an algorithm is its tunable "quantumness". As we interpolate between \acrshort{qaoa} (hybrid quantum-classical) and \acrshort{qemc} (classical, quantum-inspired), the ability to selectively adjust the degree of both could prove to be advantageous. As part of a more long-term perspective (not in this thesis), I may explore the possibility of generalizing this algorithm to tackle additional combinatorial problems, such as Max-$k$-Cut. Throughout my thesis, I will rigorously test the algorithm using classical simulations of quantum machines, aiming to identify the most effective implementation strategies considering both cost and ansatz considerations.

\subsection{Algorithm Description \& Workflow}
\label{subsection:iQAQE Description_Workflow}
A rough sketch of the workflow, in its simplest form, is provided below:
\begin{enumerate}
    \item Select the number of qubits: \texttt{n\_qubits}$ = n \in \left[\log_2{(N)}, N\right]$, where $N$ refers to the graph's number of nodes;
    \item Select the cardinality of the lists, to associate with each graph node: \texttt{list\_cardinality}$ = c \in \left[1, 2^{n} - 1\right]$, where $n$ represents the chosen number of qubits. Note that $c$ is taken to be the same for all the nodes, although this could change in future implementations;
    \item Assignment/mapping â€“ from basis states to the lists: $c$ basis states are assigned to each graph node;
    \item To obtain each node's probability: sum the probabilities of the basis states in the list (and normalize the results, so they add to $1$);
    \item Keep the same cost function and ansatz as in the \acrshort{qemc} algorithm (just adapt the ansatz to the correct number of qubits).
\end{enumerate}

I will now provide some more information on each of these steps.

\subsubsection*{Selecting the number of qubits}
In selecting the number of qubits, we allow for any intermediate value between the \acrshort{qemc} \cite{tenecohen2023variational} ($\log_2{(N)}$) and \acrshort{qaoa} \cite{farhi2014quantum} ($N$) limits. This should give us more flexibility regarding the degree of "quantum-ness" that we want our algorithm to exhibit. This is to be understood in the context of \acrshort{qemc} being entirely classical, whereas \acrshort{qaoa} is hybrid, quantum-classical. As such, by choosing a number of qubits in between these two limits, we expect our algorithm to be hybrid, in terms of its quantum nature. In addition to this, the number of qubits, alongside the ansatz, will also influence the expressivity of the model. If one opts for a \acrshort{qemc}-type exponential compression, not only does that render the scheme classically simulable in an efficient manner, but it also hinders its expressivity \cite{tenecohen2023variational}. One way to fight back against this would be to use more layers in the ansatz (if it allows for this). However, as this would require greater circuit depths, we might run into trouble trying to implement this in actual quantum hardware, in the current \acrshort{nisq} era. On the other hand, we also do not want to use all the $N$ (\acrshort{qaoa}) qubits, as this quickly becomes impractical for larger graph instances. (Think hundreds of nodes upwards.) With all that being said, we should look for the perfect balance between the two limits that provides us with the best results. This might vary depending on the specific graph instance that we are solving for.

Another thing to keep in mind, which is connected to the next point in our workflow, is that all of this depends on the type of encoding that we end up choosing. If we opt for rather specific means of encoding each node's color, or set (e.g., expectation values of Pauli strings, like in \cite{sciorilli2024largescale}), this will \textit{a priori} restrict the number of qubits that we use. (In the case of \cite{sciorilli2024largescale}, the Pauli string encoding automatically enforces a polynomial compression on the number of qubits.) So far, we've served ourselves of \acrshort{qemc}'s probability threshold encoding scheme, which relies only on the nodes' probabilities. (The nodes' colours are, then, decided depending on whether they are above, or below, the threshold: $p_{th} = \frac{1}{2B}$, for a chosen $B$ value.) This gives us more flexibility, in the sense that we are, then, free to choose how to obtain the nodes' probabilities from the basis states'\footnote{This matter of going from the basis states' probabilities to the nodes' is another, whole can of worms. We'll discuss this, in-depth, in point 4.}.

\subsubsection*{Selecting the cardinality of the lists}
In case it wasn't crystal clear by now, we associate a list of basis states to each graph node, from which we shall extract the node's corresponding probability value (used to, afterwards, define its colour, based on the aforementioned probability threshold encoding scheme). The cardinality, $c$, is chosen to be in the interval $\left[1, 2^{n-1}\right]$, where $n$ represents the number of qubits. Once again, this is to be understood as an interpolation between the \acrshort{qemc} ($1$) and \acrshort{qaoa} ($2^{n-1}$) limits. \textit{A priori}, it is not possible to know which values of $c$ would be the optimal, as the algorithm's performance depends on many, interconnected factors. Namely, the number of qubits, ansatz, cost function, colour encoding, etc. In any case, in an attempt to study this performance, as a function of the values of $c$, we perform grid-searches on this parameter.

\subsubsection*{Assignments/mapping}
There is also quite some complexity in how we go about this mapping from basis states to lists. For now, we've settled for doing it in a random fashion, attributing $c$, random, basis states, generated from the $n$ selected qubits, to each of the $N$ graph nodes. In doing so, we only make sure that all the basis states are used at least once, so we're not discarding their information. We note, however, that there might be potential benefits in utilizing a more complex/elaborate mapping. This is a possibility that we definitely intend to explore further. As an example of one such, "special", mapping, take the \acrshort{qaoa} mapping, for instance: for each graph node, we fix a single of the $N$ qubits\footnote{Remember that in \acrshort{qaoa}, $n = N$.} to one, allowing for all the possible, remaining ($2^{N-1}$) permutations of the remaining qubits. Each of these lists (of $2^{N-1}$ elements) will be associated to one graph node, with each node having a different qubit fixed to one.

\subsubsection*{Obtaining the nodes' probabilities from the basis states'}
Above, it is mentioned that we simply add the probabilities of each node's associated basis states to obtain a final node probability, which is, naturally, normalized afterwards. This is the most basic way we could go about doing this. Alternatively, there might be hidden merits in finding more elaborate ways of computing these nodes' probabilities. As a matter of example, one could make use of the arithmetic (or geometric) average of the basis states' probabilities to obtain the nodes' (again, followed by normalization). This is something that is worth spending some time on, which we intend to pursue further. However, one must be very careful when designing these schemes, as in certain circumstances a mismatch between the ansatz and this encoding (which will influence the objective function's value) can lead to constant probabilities for the nodes. Well, independent probabilities (implying a constant cost) mean we cannot optimize the variational circuit, so tread carefully. Additionally, keep in mind that the normalization process itself might also kill the probabilities' dependence on the variational parameters (under certain scenarios): one more thing to be wary of\footnote{This actually happened once, while we were testing using the \acrshort{qaoa} mapping and ansatz, together with QEMC's cost function and probability threshold encoding scheme. This had been a test to try to recover the \acrshort{qaoa} limit, from the \acrshort{iqaqe} algorithm, but it failed magnificently (in this specific formulation).}.

\subsubsection*{Cost function and ansatz}
For now, we make use of the \acrshort{qemc} cost function, based on the previously mentioned probability threshold encoding scheme:
\begin{equation}
    L(\{p(i)\}) = \sum_{\stackrel{j < k:}{\{j,k\}\in E}}\left[\left(d(j,k)-\frac{1}{B}\right)^{2}+\left(s(j,k)-\frac{1}{B}\right)^{2}\right],
\end{equation}
where $d(j,k) = |p(j) - p(k)|$ and $s(j, k) = p(j) + p(k)$ are the absolute difference and sum of the corresponding nodes' probabilities. The idea is that as both $d(j, k)$ and $s(j, k)$ tend towards $1/B$, the probability of one node approaches zero (distinctive "Set 0"), while the probability of the other node approaches $1/B$ (distinctive "Set 1"), without specifying which is which. Ultimately, just like for \acrshort{qaoa}, connections between nodes of different sets are favoured. Note, however, that this probability threshold encoding scheme assumes, \textit{a priori}, that one of the sets ("Set 1") has $B$ nodes\footnote{This is a value that we are free to choose.}, which may not be true for the MaxCut partition. In the unluckiest of scenarios, we might be required to iterate through all potential values of $B\,=\,1,...,\left\lfloor{\frac{N}{2}}\right\rfloor$ (Although, in practice, this should never happen, if $B$ is chosen carefully.) Frequently, though, it is perfectly reasonable to set $B = N/2$, and we shall use this as our starting point.

Provided our current technique for mapping the basis states to the nodes' lists, it made sense for us to use the \acrshort{qemc} cost function, instead of \acrshort{qaoa}'s, as the latter relies on a problem Hamiltonian, defined on $N$ qubits, which we might not have, depending on our choice of $n$. (More often than not, this will be the case: $n < N$. After all, we're also looking to reduce the number of qubits, so it wouldn't make sense to keep $n = N$.)

For similar reasons, we also make use of the "Strongly Entangling Layers" ansatz, featured in the \acrshort{qemc} scheme. This problem-agnostic ansatz allows us to be flexible in the number of qubits that we choose, being more adequate for this algorithm's implementation, when compared to \acrshort{qaoa}'s problem-inspired ansatz. Nevertheless, there are plans to attempt to develop more dynamic ansÃ¤tze, which would be correlated to each individual mapping that is performed. Ideally, this would increase the algorithm's performance, by taking into account formulation-specific information. One should also note that this might require an equally adapted objective function, developed with these aspects in mind.

\subsubsection*{Final notes}
The \acrshort{iqaqe} algorithm, as it is enunciated here, has already proven to yield reasonable results. Nevertheless, these were not systematically better than either \acrshort{qaoa} or \acrshort{qemc}. More testing is required to fine tune the values of $n$ and $c$, as well as the number of layers and Adam's learning rate, for each specific graph instance. This is something that will require a more in-depth analysis of the algorithm, so we can find an efficient and systematic way to do so. (Can explore grid-searches, e.g.) Further analysis on how the number of shots impacts the algorithm's performance are also due, as this is something we intend to improve relative to \acrshort{qemc}, which is especially reliant on a large number of shots per iteration, as it requires estimates of the circuit's output's probability distribution.

% Tomorrow, 14/05, I should go over all this section! Re-read everything and possibly shorten some of this. There will, for sure, be things that I want to remove/change, e.g.

% Describe iQAQE - Explain how it works, its advantages and disadvantages, and its potential applications. Also, mention how iQAQE has many degrees of freedom that can be tuned, which led to the development of many variations of iQAQE, springing from the original idea. These will be described in the \nameref{chapter:Schemes_and_Results} chapter.

% In the PIC2 report, I sort of contradict myself in the end when I mention that "[...] it is somewhat inefficient to iterate over the possible $B$ values [...]". I should correct this (just remove this sentence).

% Sub-lists' cardinalities interval: $[1, 2^N -1]$. In the PIC2 report, it states $[1, 2^{N -1}]$, which is, indeed, what I used for the simulations. However, there's no reason why we shouldn't be allowed to consider $2^N -1$ maximum number of basis states per list. I should put this disclaimer somewhere in here (Thesis).

% In the "Motivation behind this work" section in the PIC2 report, there's a number of things that need to be re-written, before being included here! Remember to do this! (Inefficient $B$ iterations, better trainability - fewer parameters?, etc.)

% There's also a bit of redundancy in this chapter.